{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1pFU_D46Rw6Vxb4MTL0fCoqv28-5UPbyJ","authorship_tag":"ABX9TyP59seIK1kboO1ap4AjW9pn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import requests  # Make sure requests is installed\n","import json\n","import numpy as np\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","def download_and_load_gpt2(model_size, models_dir):\n","    # Validate model size\n","    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n","    if model_size not in allowed_sizes:\n","        raise ValueError(f\"Model size not in {allowed_sizes}\")\n","\n","    # Define paths\n","    model_dir = os.path.join(models_dir, model_size)\n","    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n","    filenames = [\n","        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n","        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n","        \"model.ckpt.meta\", \"vocab.bpe\"\n","    ]\n","\n","    # Download files\n","    os.makedirs(model_dir, exist_ok=True)\n","    for filename in filenames:\n","        file_url = os.path.join(base_url, model_size, filename)\n","        file_path = os.path.join(model_dir, filename)\n","        download_file(file_url, file_path)\n","\n","    # Load settings and params\n","    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n","    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n","    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n","\n","    return settings, params\n","\n","\n","def download_file(url, destination):\n","    try:\n","        response = requests.get(url, stream=True, verify=False)\n","        file_size = int(response.headers.get(\"content-length\", 0))\n","\n","        if os.path.exists(destination):\n","            file_size_local = os.path.getsize(destination)\n","            if file_size == file_size_local:\n","                print(f\"File already exists and is up-to-date: {destination}\")\n","                return\n","\n","        block_size = 1024  # 1KB\n","        progress_bar_description = url.split(\"/\")[-1]\n","\n","        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n","            with open(destination, \"wb\") as file:\n","                for chunk in response.iter_content(block_size):\n","                    progress_bar.update(len(chunk))\n","                    file.write(chunk)\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error downloading the file: {e}\")\n","        print(f\"Please check the URL: {url}\")\n","\n","\n","def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n","    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n","\n","    for name, _ in tf.train.list_variables(ckpt_path):\n","        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n","        variable_name_parts = name.split(\"/\")[1:]  # Skip 'model/'\n","        target_dict = params\n","        if variable_name_parts[0].startswith(\"h\"):\n","            layer_number = int(variable_name_parts[0][1:])\n","            target_dict = params[\"blocks\"][layer_number]\n","\n","        for key in variable_name_parts[1:-1]:\n","            target_dict = target_dict.setdefault(key, {})\n","\n","        last_key = variable_name_parts[-1]\n","        target_dict[last_key] = variable_array\n","\n","    return params\n","\n","\n","# --------------------------\n","# Example usage\n","# --------------------------\n","model_size = \"124M\"\n","settings, params = download_and_load_gpt2(\n","    model_size=model_size,\n","    models_dir=\"./models\"   # better to use a folder, not \"124M\" directly\n",")\n","\n","print(settings)\n","print(params.keys())\n"],"metadata":{"id":"VdAMzNaDJ5aS","executionInfo":{"status":"ok","timestamp":1757385521201,"user_tz":-330,"elapsed":52596,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"755f5f7e-d58b-4788-b55d-419ac9b5dfc7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 256kiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.70MiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 198kiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:45<00:00, 11.0MiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 10.2MiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.84MiB/s]\n","/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.82MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n","dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"]}]},{"cell_type":"markdown","source":["### Only Load model if already downloaded"],"metadata":{"id":"E2iM6UKVWsBd"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import tensorflow as tf\n","\n","def load_gpt2(model_size, models_dir):\n","    \"\"\"\n","    Load GPT-2 model settings and parameters from local directory.\n","\n","    Args:\n","        model_size (str): One of (\"124M\", \"355M\", \"774M\", \"1558M\")\n","        models_dir (str): Path to the folder where models are stored\n","\n","    Returns:\n","        settings (dict): Model hyperparameters\n","        params (dict): Model weights organized by layer\n","    \"\"\"\n","    # Paths\n","    model_dir = os.path.join(models_dir, model_size)\n","    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n","\n","    if tf_ckpt_path is None:\n","        raise FileNotFoundError(f\"No TensorFlow checkpoint found in {model_dir}\")\n","\n","    # Load settings\n","    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n","\n","    # Load parameters from checkpoint\n","    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n","    for name, _ in tf.train.list_variables(tf_ckpt_path):\n","        variable_array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n","        variable_name_parts = name.split(\"/\")[1:]  # skip 'model/'\n","        target_dict = params\n","\n","        if variable_name_parts[0].startswith(\"h\"):  # layer params\n","            layer_number = int(variable_name_parts[0][1:])\n","            target_dict = params[\"blocks\"][layer_number]\n","\n","        # Go inside nested dicts\n","        for key in variable_name_parts[1:-1]:\n","            target_dict = target_dict.setdefault(key, {})\n","\n","        # Final assignment\n","        last_key = variable_name_parts[-1]\n","        target_dict[last_key] = variable_array\n","\n","    return settings, params\n","\n","\n","# --------------------------\n","# Example usage\n","# --------------------------\n","model_size = \"1558M\"  # or \"355M\", \"774M\", \"1558M\"\n","models_dir = \"/content/drive/MyDrive/\"  # where you saved the files\n","\n","settings, params = load_gpt2(model_size, models_dir)\n","\n","print(\"Model settings:\", settings)\n","print(\"Top-level keys in params:\", params.keys())\n","print(\"Number of layers:\", len(params[\"blocks\"]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gc8oLJBEWYNZ","executionInfo":{"status":"ok","timestamp":1757386593875,"user_tz":-330,"elapsed":43380,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"1cc6938c-f153-4d5e-f8fe-ee9322b6c59e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Model settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1600, 'n_head': 25, 'n_layer': 48}\n","Top-level keys in params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n","Number of layers: 48\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-hmq5lKFEoE","executionInfo":{"status":"ok","timestamp":1757385521222,"user_tz":-330,"elapsed":18,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"98838884-45bc-46e6-d552-0db9d15e269b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.19.0\n","4.67.1\n"]}],"source":["import tensorflow as tf\n","import tqdm\n","\n","print(tf.__version__)\n","print(tqdm.__version__)"]},{"cell_type":"code","source":["GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,    # Vocabulary size\n","    \"context_length\": 1024, # Context length\n","    \"emb_dim\": 1600,         # Embedding dimension\n","    \"n_heads\":  25,          # Number of attention heads\n","    \"n_layers\": 48,         # Number of layers\n","    \"drop_rate\": 0.1,       # Dropout rate\n","    \"qkv_bias\": False       # Query-Key-Value bias\n","}"],"metadata":{"id":"sXVNE54YsW-X","executionInfo":{"status":"ok","timestamp":1757386675309,"user_tz":-330,"elapsed":10,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        assert (d_out % num_heads == 0), \\\n","            \"d_out must be divisible by num_heads\"\n","\n","        self.d_out = d_out\n","        self.num_heads = num_heads\n","        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n","\n","        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer(\n","            \"mask\",\n","            torch.triu(torch.ones(context_length, context_length),\n","                       diagonal=1)\n","        )\n","\n","    def forward(self, x):\n","        b, num_tokens, d_in = x.shape\n","\n","        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n","        queries = self.W_query(x)\n","        values = self.W_value(x)\n","\n","        # We implicitly split the matrix by adding a `num_heads` dimension\n","        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","        keys = keys.transpose(1, 2)\n","        queries = queries.transpose(1, 2)\n","        values = values.transpose(1, 2)\n","\n","        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n","        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n","\n","        # Original mask truncated to the number of tokens and converted to boolean\n","        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","\n","        # Use the mask to fill attention scores\n","        attn_scores.masked_fill_(mask_bool, -torch.inf)\n","\n","        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","        attn_weights = self.dropout(attn_weights)\n","\n","        # Shape: (b, num_tokens, num_heads, head_dim)\n","        context_vec = (attn_weights @ values).transpose(1, 2)\n","\n","        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n","        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n","        context_vec = self.out_proj(context_vec) # optional projection\n","\n","        return context_vec\n","\n","class GELU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(\n","            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n","            (x + 0.044715 * torch.pow(x, 3))\n","        ))\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n","            GELU(), ## Activation\n","            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class LayerNorm(nn.Module):\n","    def __init__(self, emb_dim):\n","        super().__init__()\n","        self.eps = 1e-5\n","        self.scale = nn.Parameter(torch.ones(emb_dim))\n","        self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        var = x.var(dim=-1, keepdim=True, unbiased=False)\n","        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n","        return self.scale * norm_x + self.shift\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.att = MultiHeadAttention(\n","            d_in=cfg[\"emb_dim\"],\n","            d_out=cfg[\"emb_dim\"],\n","            context_length=cfg[\"context_length\"],\n","            num_heads=cfg[\"n_heads\"],\n","            dropout=cfg[\"drop_rate\"],\n","            qkv_bias=cfg[\"qkv_bias\"])\n","        self.ff = FeedForward(cfg)\n","        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n","        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n","        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    def forward(self, x):\n","        # Shortcut connection for attention block\n","        shortcut = x\n","        x = self.norm1(x)\n","        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        # Shortcut connection for feed forward block\n","        shortcut = x\n","        x = self.norm2(x)\n","        x = self.ff(x)\n","        # 2*4*768\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        return x\n","        # 2*4*768\n","\n","class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.trf_blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","\n","        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(\n","            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n","        )\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits"],"metadata":{"id":"7DJMS1ugs4xx","executionInfo":{"status":"ok","timestamp":1757386692611,"user_tz":-330,"elapsed":4184,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define model configurations in a dictionary for compactness\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","# Copy the base configuration and update with specific model settings\n","model_name = \"gpt2-xl (1558M)\"  # Example model name\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","gpt = GPTModel(NEW_CONFIG)\n","\n","#setting gpt in evaluation mode\n","gpt.eval();"],"metadata":{"id":"JS3wku47sR3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def assign(left,right):\n","  if left.shape != right.shape:\n","    raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n","  return torch.nn.Parameter(torch.tensor(right))"],"metadata":{"id":"5XqSkTYctwLT","executionInfo":{"status":"ok","timestamp":1757385562154,"user_tz":-330,"elapsed":53,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","q_w,k_w,v_w=np.split((params[\"blocks\"][1]['attn']['c_attn']['w']),3,axis=-1)\n","print(v_w.shape)\n","\n","q_b,k_b,v_b=np.split((params[\"blocks\"][1]['attn']['c_attn']['b']),3,axis=-1)\n","print(q_b.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9yv-FOS8jZp","executionInfo":{"status":"ok","timestamp":1757385562173,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"265fe448-cc3f-4c67-caf9-25f94506acff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(768, 768)\n","(768,)\n"]}]},{"cell_type":"code","source":["import tiktoken\n","\n","# Load GPT-2 tokenizer\n","enc = tiktoken.get_encoding(\"gpt2\")\n","\n","# Encode text into token IDs\n","tokens = enc.encode(\"Every efforts moves you\")\n","print(tokens)\n","\n","# Decode back into text\n","text = enc.decode(tokens)\n","print(text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVcfXUHrDyiy","executionInfo":{"status":"ok","timestamp":1757385564220,"user_tz":-330,"elapsed":2046,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"de36f7c5-d897-43cc-f095-c5fdc3cb409e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[6109, 4040, 6100, 345]\n","Every efforts moves you\n"]}]},{"cell_type":"markdown","source":["### Why we take transpose of weight while assign to gpt's different element?\n","\n","TensorFlow and PyTorch store weights with different layouts.\n","\n","For linear layers, TF uses [in_dim, out_dim] while PyTorch uses [out_dim, in_dim].\n","That’s why you must .T on weights, but not on biases.\n","If you applied .T in the wrong place (e.g. also to biases), results will differ."],"metadata":{"id":"6LUa9TJcIesh"}},{"cell_type":"code","source":["import numpy as np\n","\n","def load_weights_into_gpt(gpt, params):\n","    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n","    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.weight = assign( gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n","        gpt.trf_blocks[b].att.W_key.weight = assign( gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n","        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.bias = assign( gpt.trf_blocks[b].att.W_query.bias, q_b)\n","        gpt.trf_blocks[b].att.W_key.bias = assign( gpt.trf_blocks[b].att.W_key.bias, k_b)\n","        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n","\n","        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].att.out_proj.bias = assign( gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].ff.layers[0].weight = assign( gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[0].bias = assign( gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        gpt.trf_blocks[b].ff.layers[2].weight = assign( gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[2].bias = assign( gpt.trf_blocks[b].ff.layers[2].bias,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].norm1.scale = assign( gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.trf_blocks[b].norm1.shift = assign( gpt.trf_blocks[b].norm1.shift,params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.trf_blocks[b].norm2.scale = assign( gpt.trf_blocks[b].norm2.scale,params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.trf_blocks[b].norm2.shift = assign( gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n","    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n","    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n","\n"],"metadata":{"id":"s1KlUHbNuK_j","executionInfo":{"status":"ok","timestamp":1757385564223,"user_tz":-330,"elapsed":1,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","\n","    # For-loop is the same as before: Get logits, and only focus on last time step\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # New: Filter logits with top_k sampling\n","        if top_k is not None:\n","            # Keep only top_k values\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n","\n","        # New: Apply temperature scaling\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Apply softmax to get probabilities\n","            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n","\n","            # Sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n","\n","        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n","\n","        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","            break\n","\n","        # Same as before: append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n","\n","    return idx"],"metadata":{"id":"v39DOQMHRZ53","executionInfo":{"status":"ok","timestamp":1757385564224,"user_tz":-330,"elapsed":0,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","load_weights_into_gpt(gpt, params)\n","gpt.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdPcPr6KOqYO","executionInfo":{"status":"ok","timestamp":1757385637989,"user_tz":-330,"elapsed":674,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"55791401-fe19-482e-fbc6-aeeac0bd4174"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(1024, 768)\n","  (drop_emb): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import tiktoken\n","\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n","    return encoded_tensor\n","\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0) # remove batch dimension\n","    return tokenizer.decode(flat.tolist())"],"metadata":{"id":"GXbtxsfAR-w6","executionInfo":{"status":"ok","timestamp":1757385642845,"user_tz":-330,"elapsed":2,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","token_ids = generate(\n","    model=gpt,\n","    idx=text_to_token_ids(\"Every efforts moves you\", tokenizer).to(device),\n","    max_new_tokens=25,\n","    context_size=NEW_CONFIG[\"context_length\"],\n","    top_k=50,\n","    temperature=1.4\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"iyTECvBIRobS","executionInfo":{"status":"ok","timestamp":1757385647800,"user_tz":-330,"elapsed":1244,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67aaca8f-ad1b-4f3f-d043-9c02cbebdfb1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," Every efforts moves you as far as the eye can see where the wind is blowing - but only now\n","\n","so your own hands may start to\n"]}]}]}