{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1757518252414,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"Goh8crZG7Y9K"},"outputs":[],"source":["\n","# import os\n","# import requests  # Make sure requests is installed\n","# import json\n","# import numpy as np\n","# import tensorflow as tf\n","# from tqdm import tqdm\n","\n","# def download_and_load_gpt2(model_size, models_dir):\n","#     # Validate model size\n","#     allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n","#     if model_size not in allowed_sizes:\n","#         raise ValueError(f\"Model size not in {allowed_sizes}\")\n","\n","#     # Define paths\n","#     model_dir = os.path.join(models_dir, model_size)\n","#     base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n","#     filenames = [\n","#         \"checkpoint\", \"encoder.json\", \"hparams.json\",\n","#         \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n","#         \"model.ckpt.meta\", \"vocab.bpe\"\n","#     ]\n","\n","#     # Download files\n","#     os.makedirs(model_dir, exist_ok=True)\n","#     for filename in filenames:\n","#         file_url = os.path.join(base_url, model_size, filename)\n","#         file_path = os.path.join(model_dir, filename)\n","#         download_file(file_url, file_path)\n","\n","#     ## We have reached here until now ---> we have downloaded the files on our local machine.\n","\n","#     # Load settings and params\n","#     tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n","#     settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n","#     params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n","\n","#     return settings, params\n","\n","# def download_file(url, destination):\n","#     try:\n","#         # Send a GET request to download the file, disabling SSL verification\n","#         response = requests.get(url, stream=True, verify=False)\n","\n","#         # Get the total file size from headers, defaulting to 0 if not present\n","#         file_size = int(response.headers.get(\"content-length\", 0))\n","\n","#         # Check if file exists and has the same size\n","#         if os.path.exists(destination):\n","#             file_size_local = os.path.getsize(destination)\n","#             if file_size == file_size_local:\n","#                 print(f\"File already exists and is up-to-date: {destination}\")\n","#                 return\n","\n","#         # Define the block size for reading the file\n","#         block_size = 1024  # 1 Kilobyte\n","\n","#         # Initialize the progress bar with total file size\n","#         progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n","#         with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n","#             # Open the destination file in binary write mode\n","#             with open(destination, \"wb\") as file:\n","#                 # Iterate over the file data in chunks\n","#                 for chunk in response.iter_content(block_size):\n","#                     progress_bar.update(len(chunk))  # Update progress bar\n","#                     file.write(chunk)  # Write the chunk to the file\n","\n","#     except requests.exceptions.RequestException as e:\n","#         print(f\"Error downloading the file: {e}\")\n","#         print(f\"Please check the URL: {url}\")\n","\n","# def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n","#     # Initialize parameters dictionary with empty blocks for each layer\n","#     params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n","\n","#     # Iterate over each variable in the checkpoint\n","#     for name, _ in tf.train.list_variables(ckpt_path):\n","#         # Load the variable and remove singleton dimensions\n","#         variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n","\n","#         # Process the variable name to extract relevant parts\n","#         variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n","\n","#         # Identify the target dictionary for the variable\n","#         target_dict = params\n","#         if variable_name_parts[0].startswith(\"h\"):\n","#             layer_number = int(variable_name_parts[0][1:])\n","#             target_dict = params[\"blocks\"][layer_number]\n","\n","#         # Recursively access or create nested dictionaries\n","#         for key in variable_name_parts[1:-1]:\n","#             target_dict = target_dict.setdefault(key, {})\n","\n","#         # Assign the variable array to the last key\n","#         last_key = variable_name_parts[-1]\n","#         target_dict[last_key] = variable_array\n","\n","#     return params\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191975,"status":"ok","timestamp":1757518444403,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"Soy9newFZV3v","outputId":"a79d45d2-d1f6-41ec-d5dd-9eb104366208"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n","Top-level keys in params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n","Number of layers: 12\n"]}],"source":["import os\n","import json\n","import numpy as np\n","import tensorflow as tf\n","\n","def load_gpt2(model_size, models_dir):\n","    \"\"\"\n","    Load GPT-2 model settings and parameters from local directory.\n","\n","    Args:\n","        model_size (str): One of (\"124M\", \"355M\", \"774M\", \"1558M\")\n","        models_dir (str): Path to the folder where models are stored\n","\n","    Returns:\n","        settings (dict): Model hyperparameters\n","        params (dict): Model weights organized by layer\n","    \"\"\"\n","    # Paths\n","    model_dir = os.path.join(models_dir, model_size)\n","    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n","\n","    if tf_ckpt_path is None:\n","        raise FileNotFoundError(f\"No TensorFlow checkpoint found in {model_dir}\")\n","\n","    # Load settings\n","    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n","\n","    # Load parameters from checkpoint\n","    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n","    for name, _ in tf.train.list_variables(tf_ckpt_path):\n","        variable_array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n","        variable_name_parts = name.split(\"/\")[1:]  # skip 'model/'\n","        target_dict = params\n","\n","        if variable_name_parts[0].startswith(\"h\"):  # layer params\n","            layer_number = int(variable_name_parts[0][1:])\n","            target_dict = params[\"blocks\"][layer_number]\n","\n","        # Go inside nested dicts\n","        for key in variable_name_parts[1:-1]:\n","            target_dict = target_dict.setdefault(key, {})\n","\n","        # Final assignment\n","        last_key = variable_name_parts[-1]\n","        target_dict[last_key] = variable_array\n","\n","    return settings, params\n","\n","\n","# --------------------------\n","# Example usage\n","# --------------------------\n","model_size = \"124M\"  # or \"355M\", \"774M\", \"1558M\"\n","models_dir = \"/content/drive/MyDrive/\"  # where you saved the files\n","\n","settings, params = load_gpt2(model_size, models_dir)\n","\n","print(\"Model settings:\", settings)\n","print(\"Top-level keys in params:\", params.keys())\n","print(\"Number of layers:\", len(params[\"blocks\"]))\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6056,"status":"ok","timestamp":1757518450455,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"kYe6bKR6dINc","outputId":"66116efe-8b88-4504-c9e7-92be954aa802"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Label                                               Text\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."],"text/html":["\n","  <div id=\"df-b18d2eb7-8b3e-41af-a56d-2a9a11797865\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b18d2eb7-8b3e-41af-a56d-2a9a11797865')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b18d2eb7-8b3e-41af-a56d-2a9a11797865 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b18d2eb7-8b3e-41af-a56d-2a9a11797865');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-88267ec1-70d9-497b-b50a-6dbc02cf6562\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88267ec1-70d9-497b-b50a-6dbc02cf6562')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-88267ec1-70d9-497b-b50a-6dbc02cf6562 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","import tiktoken\n","tokenizer= tiktoken.get_encoding(\"gpt2\")\n","df = pd.read_csv(\n","    \"/content/drive/MyDrive/Email-classification-dataset-for-LLM/SMSSpamCollection\",\n","    sep=\"\\t\",\n","    header=None,\n","    names=[\"Label\", \"Text\"]\n",")\n","df.head(5)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1757518450473,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"WI4LQmdOev3E","outputId":"43e97867-b0b4-48a7-eed1-5338a525f05e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label\n","ham     4825\n","spam     747\n","Name: count, dtype: int64\n"]}],"source":["print(df['Label'].value_counts())"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1757518450513,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"S3ZGILb5uqrD","outputId":"e602ac23-a423-4339-d882-d99b853c8e5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1494, 2)"]},"metadata":{},"execution_count":5}],"source":["num_spam= df[df['Label'] == \"spam\"].shape[0]\n","ham_subst= df[df['Label']== \"ham\"].sample(num_spam,random_state=123)\n","balance_df= pd.concat([ham_subst,df[df['Label'] == \"spam\"]])\n","balance_df.shape\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1757518450536,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"DzqrOGDHv3i1","outputId":"73d70ea5-76c2-4c91-9658-3105682a0308"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4307    0\n","4138    0\n","4831    0\n","4461    0\n","5440    0\n","       ..\n","5537    1\n","5540    1\n","5547    1\n","5566    1\n","5567    1\n","Name: Label, Length: 1494, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4307</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4138</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4831</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4461</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5440</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5537</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5540</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5547</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5566</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1494 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}],"source":["balance_df['Label'] = balance_df['Label'].map({'ham':0,'spam':1})\n","balance_df['Label']"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1757518450557,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"zBWAUa29w3R8","outputId":"06969b34-472e-4a2a-ce28-9ea9139bc59b"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Label                                               Text\n","0      0                Dude how do you like the buff wind.\n","1      0  Tessy..pls do me a favor. Pls convey my birthd...\n","2      1  Reminder: You have not downloaded the content ...\n","3      1  Got what it takes 2 take part in the WRC Rally...\n","4      1  Shop till u Drop, IS IT YOU, either 10K, 5K, £...\n","      Label                                               Text\n","1194      1                     85233 FREE>Ringtone!Reply REAL\n","1195      1  Ur cash-balance is currently 500 pounds - to m...\n","1196      1  Thanks for your ringtone order, reference numb...\n","1197      0                We live in the next  &lt;#&gt; mins\n","1198      1  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...\n","      Label                                               Text\n","1045      1  Mila, age23, blonde, new in UK. I look sex wit...\n","1046      1  Hungry gay guys feeling hungry and up 4 it, no...\n","1047      0  Ugh. Gotta drive back to sd from la. My butt i...\n","1048      0  Please leave this topic..sorry for telling that..\n","1049      1  We tried to contact you re our offer of New Vi...\n"]}],"source":["balance_df = balance_df.sample(frac=1, random_state=123).reset_index(drop=True)\n","\n","train_end = int(len(balance_df.Label) * 0.7)\n","val_end = train_end + int(len(balance_df.Label) * 0.1)\n","\n","train_df = balance_df[:train_end]\n","validation_df = balance_df[train_end:val_end]\n","test_df = balance_df[val_end:]\n","\n","train_df.to_csv(\"train.csv\", index=None)\n","validation_df.to_csv(\"validation.csv\", index=None)\n","test_df.to_csv(\"test.csv\", index=None)\n","\n","print(train_df.head(5))\n","print(test_df.head(5))\n","print(validation_df.head(5))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4613,"status":"ok","timestamp":1757518455174,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"nHdoiVHw09pr"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","\n","class SpamDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n","        self.data = pd.read_csv(csv_file)\n","\n","        # Pre-tokenize texts\n","        self.encoded_texts = [\n","            tokenizer.encode(text) for text in self.data[\"Text\"]\n","        ]\n","\n","        if max_length is None:\n","            self.max_length = self._longest_encoded_length()\n","        else:\n","            self.max_length = max_length\n","\n","            # Truncate sequences if they are longer than max_length\n","            self.encoded_texts = [\n","                encoded_text[:self.max_length]\n","                for encoded_text in self.encoded_texts\n","            ]\n","\n","        # Pad sequences to the longest sequence\n","        self.encoded_texts = [\n","            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n","            for encoded_text in self.encoded_texts\n","        ]\n","\n","    def __getitem__(self, index):\n","        encoded = self.encoded_texts[index]\n","        label = self.data.iloc[index][\"Label\"]\n","        return (\n","            torch.tensor(encoded, dtype=torch.long),\n","            torch.tensor(label, dtype=torch.long)\n","        )\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def _longest_encoded_length(self):\n","        max_length = 0\n","        for encoded_text in self.encoded_texts:\n","            encoded_length = len(encoded_text)\n","            if encoded_length > max_length:\n","                max_length = encoded_length\n","        return max_length"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1757518455456,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"fQBe0Iyy6B4C","outputId":"c984825a-e0fc-4611-e394-16b734920463"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Label                                               Text\n","0      1                     85233 FREE>Ringtone!Reply REAL\n","1      1  Ur cash-balance is currently 500 pounds - to m...\n","2      1  Thanks for your ringtone order, reference numb...\n","3      0                We live in the next  &lt;#&gt; mins\n","4      1  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N..."],"text/html":["\n","  <div id=\"df-17bd6b67-18ff-4226-beac-b1dca4205fa4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>85233 FREE&gt;Ringtone!Reply REAL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Ur cash-balance is currently 500 pounds - to m...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Thanks for your ringtone order, reference numb...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>We live in the next  &amp;lt;#&amp;gt; mins</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17bd6b67-18ff-4226-beac-b1dca4205fa4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-17bd6b67-18ff-4226-beac-b1dca4205fa4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-17bd6b67-18ff-4226-beac-b1dca4205fa4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-e66abc80-aef7-48a3-8f34-6942a5a7b90a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e66abc80-aef7-48a3-8f34-6942a5a7b90a')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-e66abc80-aef7-48a3-8f34-6942a5a7b90a button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 293,\n        \"samples\": [\n          \"Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed \\u00a31000 cash or \\u00a35000 prize!\",\n          \"Update_Now - 12Mths Half Price Orange line rental: 400mins...Call MobileUpd8 on 08000839402 or call2optout=J5Q\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["train_dataset= SpamDataset(csv_file=\"train.csv\",max_length=None,tokenizer=tokenizer)\n","test_dataset= SpamDataset(csv_file=\"test.csv\",max_length=None,tokenizer=tokenizer)\n","val_dataset=SpamDataset(csv_file=\"validation.csv\",max_length=None,tokenizer=tokenizer)\n","\n","df= pd.read_csv(\"test.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1757518455464,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"J8rdybsF8tcW"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","num_workers= 0\n","batch_size=8\n","train_loader=DataLoader(\n","    dataset=train_dataset,\n","    shuffle=True,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=True\n",")\n","test_loader=DataLoader(\n","    dataset=test_dataset,\n","    shuffle=True,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=False\n",")\n","val_loader=DataLoader(\n","    dataset=val_dataset,\n","    shuffle=True,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=False\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1757518455633,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"769ibw0RUHjY"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        assert (d_out % num_heads == 0), \\\n","            \"d_out must be divisible by num_heads\"\n","\n","        self.d_out = d_out\n","        self.num_heads = num_heads\n","        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n","\n","        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer(\n","            \"mask\",\n","            torch.triu(torch.ones(context_length, context_length),\n","                       diagonal=1)\n","        )\n","\n","    def forward(self, x):\n","        b, num_tokens, d_in = x.shape\n","\n","        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n","        queries = self.W_query(x)\n","        values = self.W_value(x)\n","\n","        # We implicitly split the matrix by adding a `num_heads` dimension\n","        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","        keys = keys.transpose(1, 2)\n","        queries = queries.transpose(1, 2)\n","        values = values.transpose(1, 2)\n","\n","        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n","        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n","\n","        # Original mask truncated to the number of tokens and converted to boolean\n","        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","\n","        # Use the mask to fill attention scores\n","        attn_scores.masked_fill_(mask_bool, -torch.inf)\n","\n","        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","        attn_weights = self.dropout(attn_weights)\n","\n","        # Shape: (b, num_tokens, num_heads, head_dim)\n","        context_vec = (attn_weights @ values).transpose(1, 2)\n","\n","        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n","        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n","        context_vec = self.out_proj(context_vec) # optional projection\n","\n","        return context_vec\n","\n","class GELU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(\n","            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n","            (x + 0.044715 * torch.pow(x, 3))\n","        ))\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n","            GELU(), ## Activation\n","            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class LayerNorm(nn.Module):\n","    def __init__(self, emb_dim):\n","        super().__init__()\n","        self.eps = 1e-5\n","        self.scale = nn.Parameter(torch.ones(emb_dim))\n","        self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        var = x.var(dim=-1, keepdim=True, unbiased=False)\n","        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n","        return self.scale * norm_x + self.shift\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.att = MultiHeadAttention(\n","            d_in=cfg[\"emb_dim\"],\n","            d_out=cfg[\"emb_dim\"],\n","            context_length=cfg[\"context_length\"],\n","            num_heads=cfg[\"n_heads\"],\n","            dropout=cfg[\"drop_rate\"],\n","            qkv_bias=cfg[\"qkv_bias\"])\n","        self.ff = FeedForward(cfg)\n","        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n","        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n","        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    def forward(self, x):\n","        # Shortcut connection for attention block\n","        shortcut = x\n","        x = self.norm1(x)\n","        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        # Shortcut connection for feed forward block\n","        shortcut = x\n","        x = self.norm2(x)\n","        x = self.ff(x)\n","        # 2*4*768\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        return x\n","        # 2*4*768\n","\n","class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.trf_blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","\n","        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(\n","            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n","        )\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":119,"status":"ok","timestamp":1757518455756,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"nuK9Luge6Xwj"},"outputs":[],"source":["def assign(left,right):\n","  if left.shape != right.shape:\n","    raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n","  return torch.nn.Parameter(torch.tensor(right))\n","\n","import numpy as np\n","\n","def load_weights_into_gpt(gpt, params):\n","    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n","    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.weight = assign( gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n","        gpt.trf_blocks[b].att.W_key.weight = assign( gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n","        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.bias = assign( gpt.trf_blocks[b].att.W_query.bias, q_b)\n","        gpt.trf_blocks[b].att.W_key.bias = assign( gpt.trf_blocks[b].att.W_key.bias, k_b)\n","        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n","\n","        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].att.out_proj.bias = assign( gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].ff.layers[0].weight = assign( gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[0].bias = assign( gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        gpt.trf_blocks[b].ff.layers[2].weight = assign( gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[2].bias = assign( gpt.trf_blocks[b].ff.layers[2].bias,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].norm1.scale = assign( gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.trf_blocks[b].norm1.shift = assign( gpt.trf_blocks[b].norm1.shift,params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.trf_blocks[b].norm2.scale = assign( gpt.trf_blocks[b].norm2.scale,params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.trf_blocks[b].norm2.shift = assign( gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n","    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n","    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n","\n","def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","\n","    # For-loop is the same as before: Get logits, and only focus on last time step\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # New: Filter logits with top_k sampling\n","        if top_k is not None:\n","            # Keep only top_k values\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n","\n","        # New: Apply temperature scaling\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Apply softmax to get probabilities\n","            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n","\n","            # Sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n","\n","        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n","\n","        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","            break\n","\n","        # Same as before: append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n","\n","    return idx\n","\n","def generate_text_simple(model, idx, max_new_tokens, context_size):\n","    # idx is (batch, n_tokens) array of indices in the current context\n","\n","    ###Input batch:\n"," ###tensor([[6109, 3626, 6100,  345],\n","        ##[6109, 1110, 6622,  257]])\n","\n","    for _ in range(max_new_tokens):\n","\n","        # Crop current context if it exceeds the supported context size\n","        # E.g., if LLM supports only 5 tokens, and the context size is 10\n","        # then only the last 5 tokens are used as context\n","        idx_cond = idx[:, -context_size:]\n","\n","        # Get the predictions\n","        with torch.no_grad():\n","            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n","\n","        # Focus only on the last time step\n","        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n","        logits = logits[:, -1, :]\n","\n","        # Apply softmax to get probabilities\n","        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n","\n","        # Get the idx of the vocab entry with the highest probability value\n","        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n","\n","        # Append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n","\n","    return idx\n","\n","\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0) # remove batch dimension\n","    return tokenizer.decode(flat.tolist())\n","\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n","    return encoded_tensor"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1757518455766,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"PSbSDJVrUSIp"},"outputs":[],"source":["CHOOSE_MODEL = \"gpt2-small (124M)\"\n","INPUT_PROMPT = \"Every effort moves\"\n","\n","BASE_CONFIG = {\n","    \"vocab_size\": 50257,     # Vocabulary size\n","    \"context_length\": 1024,  # Context length\n","    \"drop_rate\": 0.0,        # Dropout rate\n","    \"qkv_bias\": True         # Query-key-value bias\n","}\n","\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n","\n","assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n","    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n","    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n","    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1757518455774,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"Bsadmb-87kBn"},"outputs":[],"source":["# model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n","# setting, params = download_and_load_gpt2(model_size=model_size,models_dir= \"124M\")"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2088,"status":"ok","timestamp":1757519101667,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"G4RGpx9A9Ozj","outputId":"cb1cdfe9-76f7-4a20-92fd-1057407659b2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(1024, 768)\n","  (drop_emb): Dropout(p=0.0, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.0, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":31}],"source":["model =GPTModel(BASE_CONFIG)\n","load_weights_into_gpt(model,params)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6620,"status":"ok","timestamp":1757518966327,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"hm4GJJyCE2t4","outputId":"78f03086-cd51-47f9-b226-ebc8f377730f"},"outputs":[{"output_type":"stream","name":"stdout","text":["My name is John. I'm a man of God. I'm a man of God. I'm a man of God. I'm\n"]}],"source":["text_1 = \"My name is\"\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(text_1, tokenizer),\n","    max_new_tokens=25,\n","    context_size=BASE_CONFIG[\"context_length\"]\n",")\n","\n","print(token_ids_to_text(token_ids, tokenizer))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1757518969894,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"pD2ChRiAIvA2"},"outputs":[],"source":["for param in model.parameters():\n","  param.requires_grad = False # this parameters are freezed"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1757518973725,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"yG14WpfrYQKY"},"outputs":[],"source":["torch.manual_seed(123)\n","num_class=2\n","\n","# Setting output dimnesion 50257 ---> 2\n","model.out_head= torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"],out_features=num_class)\n","\n","#Now we finetue last transformer block\n","for parma in model.trf_blocks[-1].parameters():\n","  param.requires_grad = True\n","for param in model.final_norm.parameters():\n","  param.requires_grad= True\n"]},{"cell_type":"markdown","metadata":{"id":"0nYkTmiFoF0V"},"source":["### CALCULATING CLASSIFICATION LOSS AND ACCURAY"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1757518975544,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"_NiIwTr6lrfg"},"outputs":[],"source":["def calc_accuracy_loader(data_loader,model,device,num_batches=None):\n","  model.eval()\n","  correct_prediction,num_examples= 0,0\n","  if num_batches is None:\n","    num_batches= len(data_loader)\n","  else:\n","    num_batches= min(num_batches,len(data_loader))\n","  for i,(input_batch,target_batch) in enumerate(data_loader):\n","    if i < num_batches:\n","      input_batch ,target_batch= input_batch.to(device),target_batch.to(device)\n","\n","      with torch.no_grad():\n","        logits= model(input_batch)[:,-1,:]\n","        predicted_labels = torch.argmax(logits,dim=-1)\n","\n","        num_examples += predicted_labels.shape[0]\n","        correct_prediction +=(predicted_labels == target_batch).sum().item()\n","    else:\n","      break\n","  return correct_prediction/ num_examples\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1757518977451,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"utLGrgR-xWbM"},"outputs":[],"source":["def calc_loss_batch(input_batch,target_batch,model,device):\n","  input_batch, target_batch= input_batch.to(device), target_batch.to(device)\n","  logits = model(input_batch)[:,-1,:] #Logits of last output vector\n","  loss= torch.nn.functional.cross_entropy(logits,target_batch)\n","  return loss"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1757518978382,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"fi7BSplCOIOm"},"outputs":[],"source":["def calc_loss_loader(data_loader,model,device,num_batches =None):\n","  total_loss= 0.\n","  if len(data_loader)==0:\n","    return float('nan')\n","  elif num_batches == None:\n","    num_bathces= len(data_loader)\n","  else:\n","    num_batches= min(num_batches,len(data_loader))\n","\n","    for i,(input_batch,target_batch) in enumerate(data_loader):\n","      if i < num_batches:\n","        loss= calc_loss_batch(input_batch,target_batch,model,device)\n","        total_loss +=loss.item()\n","      else:\n","        break\n","  return total_loss / num_batches\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eDNKLT17P5to"},"source":["## FINETUNING THE MODEL ON SUPERVISED DATA"]},{"cell_type":"markdown","metadata":{"id":"ps4nna32P-k9"},"source":["Step 1: Set model to training mode\n","\n","Step 2: Reset loss gradients from previous batch iteration\n","\n","Step 3: Calculate loss gradients\n","\n","Step 4: Update model weights using loss gradients\n","\n","Step 5: New: track examples instead of tokens\n","\n","Step 6: Optional evaluation step\n","\n","Step 7: Calculate accuracy after each epoch"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1757518982551,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"Mp4O_u5fQCFW"},"outputs":[],"source":["# Overall the same as `train_model_simple` in chapter 5\n","def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n","                            eval_freq, eval_iter):\n","    # Initialize lists to track losses and examples seen\n","    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n","    examples_seen, global_step = 0, -1\n","\n","    # Main training loop\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","\n","        for input_batch, target_batch in train_loader:\n","            # ✅ Move data to device (GPU or CPU)\n","            input_batch = input_batch.to(device)\n","            target_batch = target_batch.to(device)\n","\n","            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward() # Calculate loss gradients\n","            optimizer.step()\n","            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n","            global_step += 1\n","\n","            # Optional evaluation step\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(\n","                    model, train_loader, val_loader, device, eval_iter)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n","\n","        # Calculate accuracy after each epoch\n","        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n","        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n","        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n","        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n","        train_accs.append(train_accuracy)\n","        val_accs.append(val_accuracy)\n","\n","    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1757518984796,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"jT23QHaTX7S6"},"outputs":[],"source":["# Same as chapter 5\n","def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n","        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n","    model.train()\n","    return train_loss, val_loss"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4oiyOXPZGJK","executionInfo":{"status":"ok","timestamp":1757519318429,"user_tz":-330,"elapsed":207909,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"}},"outputId":"c3775799-c3bf-46fc-907a-bfb068d758bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ep 1 (Step 000000): Train loss 3.917, Val loss 5.129\n","Ep 1 (Step 000050): Train loss 0.368, Val loss 0.303\n","Ep 1 (Step 000100): Train loss 0.049, Val loss 0.414\n","Training accuracy: 87.50% | Validation accuracy: 90.00%\n","Ep 2 (Step 000150): Train loss 0.221, Val loss 0.141\n","Ep 2 (Step 000200): Train loss 0.272, Val loss 0.065\n","Ep 2 (Step 000250): Train loss 0.125, Val loss 0.127\n","Training accuracy: 97.50% | Validation accuracy: 100.00%\n","Ep 3 (Step 000300): Train loss 0.014, Val loss 0.100\n","Ep 3 (Step 000350): Train loss 0.058, Val loss 0.094\n","Training accuracy: 100.00% | Validation accuracy: 97.50%\n","Ep 4 (Step 000400): Train loss 0.003, Val loss 0.001\n","Ep 4 (Step 000450): Train loss 0.002, Val loss 0.136\n","Ep 4 (Step 000500): Train loss 0.017, Val loss 0.209\n","Training accuracy: 100.00% | Validation accuracy: 97.50%\n","Ep 5 (Step 000550): Train loss 0.000, Val loss 0.001\n","Ep 5 (Step 000600): Train loss 0.009, Val loss 0.213\n","Training accuracy: 100.00% | Validation accuracy: 95.00%\n","Training completed in 3.48 minutes.\n"]}],"source":["import time\n","\n","start_time = time.time()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(123)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n","\n","num_epochs = 5\n","train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",")\n","\n","end_time = time.time()\n","execution_time_minutes = (end_time - start_time) / 60\n","print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":205274,"status":"aborted","timestamp":1757518457633,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"_vxTxFzBjDwU"},"outputs":[],"source":["def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n","    model.eval()\n","\n","    # Prepare inputs to the model\n","    input_ids = tokenizer.encode(text)\n","    supported_context_length = model.pos_emb.weight.shape[0]\n","    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n","    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n","\n","    # Truncate sequences if they too long\n","    input_ids = input_ids[:min(max_length, supported_context_length)]\n","\n","    # Pad sequences to the longest sequence\n","    input_ids += [pad_token_id] * (max_length - len(input_ids))\n","    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n","\n","    # Model inference\n","    with torch.no_grad():\n","        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n","    predicted_label = torch.argmax(logits, dim=-1).item()\n","\n","    # Return the classified result\n","    return \"spam\" if predicted_label == 1 else \"not spam\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":205281,"status":"aborted","timestamp":1757518457640,"user":{"displayName":"Harsh Tejani","userId":"04678594043684207353"},"user_tz":-330},"id":"oPsE44IJdNfN"},"outputs":[],"source":["text_1 = (\n","    \"You are a winner you have been specially\"\n","    \" selected to receive $1000 cash or a $2000 award.\"\n",")\n","\n","print(classify_review(\n","    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n","))\n","\n","text_2 = (\n","    \"Hey, just wanted to check if we're still on\"\n","    \" for dinner tonight? Let me know!\"\n",")\n","\n","print(classify_review(\n","    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n","))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1JLoNzhfOiS4oZv9frzfQev7XnThOWGbr","authorship_tag":"ABX9TyPeT9SWFiAZUis2qIIi/5za"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}